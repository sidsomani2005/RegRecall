{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RegRecall Dataset Construction\n",
    "\n",
    "This notebook contains code to construct the RegRecall dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sidsomani/anaconda3/lib/python3.11/site-packages/pypdf/_crypt_providers/_cryptography.py:32: CryptographyDeprecationWarning: ARC4 has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.ARC4 and will be removed from cryptography.hazmat.primitives.ciphers.algorithms in 48.0.0.\n",
      "  from cryptography.hazmat.primitives.ciphers.algorithms import AES, ARC4\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pypdf import PdfReader\n",
    "from lit_scraper import scrape_sec_complaints\n",
    "from sec_complaint_parser import SECComplaintParser\n",
    "from parser_config import reg_headings\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Litigation Web Scraping\n",
    "\n",
    "First, we scrape all litigation proceedings opened by the SEC from [here](https://www.sec.gov/litigation/litreleases). After the scraping is completed, note that the documents must be moved from your default \"Downloads\" folder to a more permanent location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped non-PDF link: https://www.sec.gov/files/litigation/complaints/2025/comp26349.pdf\n",
      "Skipped non-PDF link: https://www.sec.gov/files/litigation/complaints/2025/comp26348.pdf\n",
      "Skipped non-PDF link: https://www.sec.gov/files/litigation/complaints/2025/comp26345.pdf\n",
      "Skipped non-PDF link: https://www.sec.gov/files/litigation/complaints/2025/comp26343.pdf\n",
      "Skipped non-PDF link: https://www.sec.gov/files/litigation/complaints/2025/comp26341.pdf\n",
      "Skipped non-PDF link: https://www.sec.gov/files/litigation/complaints/2025/comp26339.pdf\n",
      "Skipped non-PDF link: https://www.sec.gov/files/litigation/complaints/2025/comp26336.pdf\n",
      "Skipped non-PDF link: https://www.sec.gov/files/litigation/complaints/2025/comp26333.pdf\n",
      "Skipped non-PDF link: https://www.sec.gov/files/litigation/complaints/2024/comp26331.pdf\n",
      "Stopped\n",
      "Total size of downloaded PDFs: 0 bytes\n",
      "Total number of downloaded files: 10\n"
     ]
    }
   ],
   "source": [
    "scrape_sec_complaints()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Initial Parsing\n",
    "\n",
    "Next, the documents must be parsed to identify and extract information relating to actions taken, and violations broken.\n",
    "\n",
    "First, parse the pdfs to extract text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  9.58it/s]\n"
     ]
    }
   ],
   "source": [
    "all_texts = SECComplaintParser.get_all_pdf_texts(\"data/sec_complaints\", save_text=True, save_directory=\"data/sec_complaints_text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, if the text has already been extracted, load the text in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 7777.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 texts loaded in!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_texts = SECComplaintParser.load_pdf_texts(\"data/sec_complaints_text\")\n",
    "\n",
    "print(\"{num_texts} texts loaded in!\".format(num_texts=len(all_texts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved JSON to data/sec_complaints_json/complaints.json\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"data/sec_complaints_json\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, \"complaints.json\")\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "    json.dump(all_texts, json_file, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"Saved JSON to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us split the text up by sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sectioned_texts = SECComplaintParser.section_all_texts(all_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1. between 2019 and 2024, defendants peter scalise iii (“scalise”) and ', 'the3rdbevco inc. (“the3rdbevco”  or the “company” ), a beverage company that scalise ', 'founded, controls, and operates, perpetrated a $3.6 million  offering fraud.  ', '2. defendants misled investors about the use of the  invest or funds  and a potential ', 'collaboration with “individual 1,” a celebrity described by defendants as a “global superstar ', 'and music icon.”   ', '3. contrary to what investors were told, scalise misappropriated and misused more ', 'than $856,000 of investor funds , including for personal expenses, such as tuition, mortgage  ', 'payments , and landscaping.     ', '4. in addition, in communications to existing  investors and potential investors, ', 'defendants promoted a potential collaboration with individual 1 on a supposed rum alcohol product, using individual 1’s nickname and trademark in its product brand name  and us ing ', 'individual 1’s name, image, trademark, and music  in various promotional materials —all without ', 'authorization.  while defendants communicated  with individual 1’s brother about an case 2:25-cv-03088-wb     document 1     filed 06/17/25     page 1 of 18  ', '2 ', ' arrangement  in which he would agree to attempt to facilitate a  meeting between defendants and ', 'individual 1’s management team , there was never any deal , negotiation, discussion or any other ', 'contact between the defendants and  individual 1 or individual 1’s  management team.  ', '5. moreover, defendants also offered and sold unregistered securities without a  ', 'valid  exemption from registration.  ', '6. by engaging in the conduct described in this complaint, defendants violated, ', 'directly or indirectly, and unless enjoined will continue to violate, sections 5(a), 5(c), and 17(a) ', 'of the securities act of 1933 (“securities act”) [15 u.s.c. §§ 77e(a), 77e(c), and 77q(a)] and section 10(b) of the securities exchange act of 1934 (“exchange act”) [15 u.s.c. § 78j(b)] and rule 10b- 5 thereunder [17 c.f.r. § 240.10b- 5]. ']\n"
     ]
    }
   ],
   "source": [
    "print(sectioned_texts['comp26328'][\"complaint\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.*claimforrelief', 'prayerforrelief', 'claimsforrelief', 'claimsforaction', 'claimforrelief', '.*claimforaction', '.*causeofaction', 'count.*']\n",
      "9\n",
      "1\n",
      "['comp26345']\n"
     ]
    }
   ],
   "source": [
    "rule_section = 0\n",
    "no_rule_section = 0\n",
    "no_rule_sections = []\n",
    "\n",
    "print(reg_headings)\n",
    "\n",
    "for text_key, sectioned_text in sectioned_texts.items():\n",
    "    has_rule_section = False\n",
    "    \n",
    "    for heading in sectioned_text:\n",
    "        if SECComplaintParser.regex_fullmatch_any(heading, reg_headings):\n",
    "            has_rule_section = True\n",
    "\n",
    "    if has_rule_section:\n",
    "        rule_section += 1\n",
    "    else:\n",
    "        no_rule_section += 1\n",
    "        no_rule_sections.append(text_key)\n",
    "\n",
    "print(rule_section)\n",
    "print(no_rule_section)\n",
    "print(no_rule_sections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Section Parsing\n",
    " \n",
    "Extracting each section from each txt filing using sec_complaint_parser.py functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i want to clean the text using SECComplaintParser.clean_string\n",
    "for text_key, sectioned_text in sectioned_texts.items():\n",
    "    for heading in sectioned_text:\n",
    "        sectioned_text[heading] = SECComplaintParser.clean_string(sectioned_text[heading])\n",
    "        print(f\"Cleaned text for {text_key} under heading {heading}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
